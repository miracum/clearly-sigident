---
title: "sigident - Howto Microarray"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sigident-Howto_Microarray}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r setup}
library(sigident)
library(knitr)
```

# Prerequisites and Installation 

## Install sigident package

```{r eval=FALSE}
options('repos' = 'https://ftp.fau.de/cran/')
install.packages("devtools")
devtools::install_git("https://gitlab.miracum.org/clearly/sigident.git")
```

# Preprocessing 

## Data Preparation 

In order to use this R package and its functions, you need to prepare a merged gene expression dataset. 
This example uses the GEO lung cancer studies "GSE18842", "GSE19804" and "GSE19188", which contain in total 367 samples (197 tumor; 170 non-tumor) and 54,675 transcripts obtained by using Affymetrix GeneChip Human Genome U133 Plus 2.0 Array (platform GPL570).

### Download of GEO datasets and normalization

To use microarray datasets from the GEO database the studies can be downloaded directly executing R code. Therefore, initializing the directory and creating the required folders is needed before downloading GEO studies. The objects `targetcol` should also be entitled "target". To run this package analyzing DEGs and identifying diagnostic and prognostic gene signatures for the seperation of two groups (or subtypes, healthy vs cancer, etc) we here named `controlname` and `targetname` exemplary as "control" and "Lung Cancer". `targetcol` contains the outcome variable of interest for subsequent analysis.

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# initialize filePath:
filePath <- tempdir()
maindir <- "./geodata/"
datadir <- paste0(maindir, "data/")
dir.create(maindir)
dir.create(datadir)

# initialize more infos on the study
targetcol <- "target" # should be named "target"
controlname <- "Control"
targetname <- "Lung Cancer"
```

Insert the GEO accesion numbers of the desired GEO studies into the `getGEO()` function. This will download the datasets containing expressin data, pheno and feature data as well as the annotation of the probe sets and store it as .txt.gz files in the "data" folder. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
GSE18842 <- GEOquery::getGEO("GSE18842", destdir = datadir)
GSE19804 <- GEOquery::getGEO("GSE19804", destdir = datadir)

# extracting expressionSets
eset1 <- GSE18842[[1]]
eset2 <- GSE19804[[1]]
```

Morover, the approach enables to download raw data as CEL files, uncompress it and conduct GCRMA normalization. For this, further commands are necessary to subsequently import the CEL files into the R environment. Accordingly `esetC` represents a normalized epressionSet though only containing expression data without pheno and feature data. These data can be added later. (Don't be confused by our example. We could have downloaded the study GSE19188 directly by applying `getGEO()` instead of downlaoding the raw data and adding pheno and feature data afterwards. We just wanted to demonstrating you how to use raw data in form of CEL files)

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# download raw data, uncompress them and execute GCRMA normalization
# actually not necessary for GSE19188 but to showcase feasibility of dealing with .CEL files
GEOquery::getGEOSuppFiles("GSE19188", baseDir = filePath)
utils::untar(paste0(filePath, "/GSE19188/GSE19188_RAW.tar"), exdir=maindir)
cels <- list.files(maindir, pattern = "[gz]")
tryCatch({
  sapply(paste(maindir, cels, sep="/"), GEOquery::gunzip)
  # at this point, first the textfile "phenodata.txt must be generated
  ## For downloading raw data use the function: getGEOSuppFiles(""). After downloading and uncompressing the raw file (*_RAW.tar) we need to capture
  ## the experimental information. Therefore a text file is created in the terminal window or rather in the command line.
  system("bash -c 'ls ./geodata/*.CEL > ./geodata/phenodata.txt'")
  ## The command: ls data/*.CEL > data/phenodata.txt puts all .CEl files in one text file.
  ## After this step the normalization can be started.
}, error = function(e){
  print(e)
})

cels <- list.files(maindir, pattern = "CEL$")

celfiles <- paste0(maindir, cels)
# use justGCRMA now due to memory issues with gcrma --> justGCRMA is much more memory efficient
# https://www.rdocumentation.org/packages/gcrma/versions/2.44.0/topics/justGCRMA
esetC <- gcrma::justGCRMA(filenames = celfiles, fast = TRUE)
# call garbage collection here
gc()

# old code
#celfiles <- affy::ReadAffy(filenames = gsub("\\.gz", "", cels), celfile.path = "./geodata")
#esetC <- gcrma::gcrma(celfiles, fast = TRUE)

# esetC = now is a normalized expressionSet, but without f- and pData
# the f- and pData are transfered manually from dataset GSE19188

GSE19188 <- GEOquery::getGEO("GSE19188", destdir = datadir)

eset3 <- GSE19188[[1]]
pData3 <- Biobase::pData(eset3)
fData3 <- Biobase::fData(eset3)
Biobase::pData(esetC) <- pData3
Biobase::fData(esetC) <- fData3
colnames(Biobase::exprs(esetC)) <- colnames(Biobase::exprs(eset3))
Biobase::annotation(esetC) <- Biobase::annotation(eset3)
eset3 <- esetC
```

### Formatting the phenoData 

The phenoData of the expresssionSets need to be formatted that the phenoData columns overlap perfectly. This means that all expressionSets should contain identical columns in the same order. Not consistent columns need to get removed. For a simpler procedure we recommend only retaining phenoData columns required for the downstream analysis (e.g. targetcol and survival data). 

```{r}
# create version b, that original expressionSets persist
eset1b <- eset1
eset2b <- eset2
eset3b <- eset3

# show number of samples and phenoData columns
dim(Biobase::pData(eset1b))
dim(Biobase::pData(eset2b))
dim(Biobase::pData(eset3b))
# depict phenoData column names
colnames(Biobase::pData(eset1b))
colnames(Biobase::pData(eset2b))
colnames(Biobase::pData(eset3b))


# remove unnecessary phenoData
# rename desired column names and if necessary the column entries (as we did for 'Tumor')

# eset1b
eset1b$relation <- NULL
eset1b$characteristics_ch1 <- NULL
eset1b$`sample type:ch1` <- NULL
eset1b$`tissue:ch1` <- NULL
colnames(Biobase::pData(eset1b))[8] = targetcol
levels(eset1b[[targetcol]]) = c(controlname, targetname)
dim(eset1b)


# eset2b
eset2b$characteristics_ch1.2 <- NULL
eset2b$characteristics_ch1.3 <- NULL
eset2b$contact_department <- NULL
eset2b$characteristics_ch1 <- NULL
eset2b$`age:ch1` <- NULL
eset2b$`gender:ch1` <- NULL
eset2b$`stage:ch1` <- NULL
eset2b$`tissue:ch1` <- NULL
colnames(Biobase::pData(eset2b))[8] = targetcol
levels(eset2b[[targetcol]]) = c(controlname, targetname)
dim(eset2b)


# eset3b
eset3b$characteristics_ch1.2 <- NULL
eset3b$characteristics_ch1.3 <- NULL
eset3b$characteristics_ch1.4 <- NULL
eset3b$contact_phone <- NULL
eset3b$contact_fax <- NULL
eset3b$contact_department <- NULL
eset3b$contact_web_link <- NULL
eset3b$relation <- NULL
eset3b$source_name_ch1 <- NULL
colnames(Biobase::pData(eset3b))[9] = targetcol
levels(eset3b[[targetcol]]) = c(controlname, targetname)
pNew <- Biobase::pData(eset3b)[,c(1:7,9,8,10:29)] # reorder columns
Biobase::pData(eset3b) = pNew
dim(eset3b)

# now, all phenoData columns are consistent
cbind(colnames(Biobase::pData(eset1b)), colnames(Biobase::pData(eset2b)), 
      colnames(Biobase::pData(eset3b)))
```


## Preparations for utilizing the sigident package 

These variables need to be defined for the package functions to work. One could use them also as arguments directly in the respective function. However, we think it is more clearly to define them here at the beginning and to refer at each function to the respective variable.  


```{r}
plotdir <- "./plots/"
dir.create(plotdir)
csvdir <- "./csv/"
dir.create(csvdir)
species <- "Hs"
OrgDb <- "org.Hs.eg.db"
organism <- "hsa"
pathwayid <- "hsa04110"
seed <- 111
split <- 0.8
idtype = "affy"
```


### Extract Metadata 

The metadata are exrtracted directly from the expressionSets and are deposited for a easyier applicability in the data frame `sampleMetadata`. This data frame consists of the GEO accession numbers of the study (GPLxxx), the sample accession numbers (GSMxxx) and the `targetcol` containing the outcome of interest. 

### Extract sample metadata 

```{r}
# workaround
GSE18842_meta <- data.table::data.table(
  cbind(
    study = "GSE18842",
    sample = eset1b@phenoData@data[,"geo_accession"],
    target = as.character(eset1b@phenoData@data[,targetcol])
  )
)

GSE19804_meta <- data.table::data.table(
  cbind(
    study = "GSE19804",
    sample = eset2b@phenoData@data[,"geo_accession"],
    target = as.character(eset2b@phenoData@data[,targetcol])
  )
)

GSE19188_meta <- data.table::data.table(
  cbind(
    study = "GSE19188",
    sample = eset3b@phenoData@data[,"geo_accession"],
    target = as.character(eset3b@phenoData@data[,targetcol])
  )
)

sampleMetadata <- rbind(GSE18842_meta,
                        GSE19804_meta,
                        GSE19188_meta)
```

#### Define study metadata 

`sutdyMetadata` contains the GEO series accssion numbers of the studies and the assignment due to its usage as discovery or validation dataset. 

```{r}
studyMetadata <- data.frame(
  cbind(study = c("GSE18842", "GSE19804", "GSE19188", "GSE30219"),
        discovery = as.logical(c(1, 1, 1, 0)),
        validation = as.logical(c(0, 0, 0, 1))
  ),
  stringsAsFactors = FALSE
)
```

## Merging and Batch Correction

In this framework for merging, only genes that are present in all datasets are preserved. In our example the entire probe set of 54675 transcripts remains. `mergedset` contains the samples of the studies grouped as discovery and represents an "ExpressionSet" object describing samples, annotations and informations about the features.

```{r}
esets=c(eset1b,eset2b,eset3b)
mergedset <- sigident::merge_(esets)
```

# Discovering Batch Effects 

Batch effects are systematic non-biological variation between studies due to experimental and technical artifacts. As first visualization a boxplot is created with the included samples on the x-axis and the expression values on the y-axis. Thereby, considerable discrepancies between the three studes can already be recognized apparently. 
A more powerfull approach for batch effect detection is conducting a guided Principle Component Analysis (gPCA) implemented in the [gPCA](https://CRAN.R-project.org/package=gPCA) package.

## Visualize batch effect

```{r}
# visualize log2 transformed expression values of the merged data set as boxplot
filename <- paste0(plotdir, "boxplot_merged_data.jpeg")
jpeg(filename, width = 2000, height = 1000, res = 150, units = "px")
boxplot(mergedset@assayData$exprs, main = "Merged data before batch correction", 
        xlab = "Samples", ylab ="Expression value")
dev.off()
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```


```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# conducting gPCA for batch effect detection
DF <- mergedset@assayData$exprs

# define batches with number of samples
batch <- sigident::createBatch_(studyMetadata = studyMetadata,
                                sampleMetadata = sampleMetadata)

gPCA_before <- sigident::batchDetection_(mergeset = DF,
                                          batch = batch)
filename <- paste0(plotdir, "PCplot_before.png")
sigident::createBatchPlot_(correction_obj = gPCA_before,
                           filename = filename,
                           time = "before")
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```


In order to correct for occurring batch effects and other unwanted variation in high-throughput experiments the `ComBat` function from the [sva](10.1093/bioinformatics/bts034) package is conducted. The `ComBat` function adjusts for known batches using an empirical Bayesian framework[1].  

```{r message=FALSE, warning=FALSE, error=FALSE}
table(mergedset@phenoData@data[[targetcol]])

# generate list dd with diagnosis and design
dd <- sigident::createDiagnosisDesignBatch_(sampleMetadata = sampleMetadata,
                                            studyMetadata = studyMetadata,
                                            controlname = controlname,
                                            targetname = targetname,
                                            targetcol = targetcol)
diagnosis <- dd$diagnosis
length(diagnosis)
table(diagnosis)

design <- dd$design


# check batch assignment
table(batch)
length(batch)

# removing batch effects computing linear models, take variance between the diagnosis into consideration

mergeset <- sigident::batchCorrection_(mergedset = mergedset,
                                       batch = batch,
                                       design = design,
                                       idtype = idtype)

dim(mergeset)
```

`mergeset` results as output of the above described merging approach and represents a matrix containing batch corrected expression data with genes in the rows and samples in the columns, not an ExpressionSet any more. During this process the affy probes are mapped to the appropriate Entrez ID and empty and replicated character strings get removed. Therefore, only 21879 Entrez IDs remain.  


## Visualize batch effect removal

Creating a boxplot and a gPCA plot with `mergeset` points out that no batch effect is present no more. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "import_boxplot.png")
sigident::createImportBoxplot_(mergeset, filename)
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```


```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
gPCA_after <- sigident::batchDetection_(mergeset = mergeset,
                                        batch = batch)
filename <- paste0(plotdir, "PCplot_after.png")
sigident::createBatchPlot_(correction_obj = gPCA_after,
                           filename = filename,
                           time = "after")
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```


```{r results='hide'}
# remove unneeded objects
rm("DF", "GSE18842_meta", "GSE19188_meta", "GSE19804_meta")
# also no further purpose, but takes a lot of memory and may slow down your computer
rm("eset1", "eset1b", "eset2", "eset2b", "eset3", "eset3b", "esets", "GSE18842", "GSE19188", "GSE19804", "fData3", "esetC")
gc()
```


# DEG Analysis 

A common task proceeding expression data is to perform statistical analysis to discover quantitative changes in expression levels between experimental groups. For this reason we here offer the identification of differentially expressed genes (DEGs) based on the limma package. In order to multiple testing correction we considered the p-value adjustment by conducting the "BH" method, which controls the expected false discovery rate (FDR).  
A heatmap based on the selected DEGs is created and clear differences regarding the expression profiles between the groups (Control and Lung Cancer) can be recognized. 


```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# define the false discovery rate here
FDR <- 0.05

genes <- sigident::identifyDEGs_(mergeset = mergeset,
                                 design = design,
                                 qValue = FDR)

# heatmap creation
filename <- paste0(plotdir, "DEG_heatmap.png")
# create colors for map
ht_colors <- sigident::colorHeatmap_(sampleMetadata = sampleMetadata,
                                     studyMetadata = studyMetadata,
                                     targetcol = targetcol,
                                     controlname = controlname) # cancer = red
sigident::createDEGheatmap_(mergeset = mergeset,
                            genes = genes,
                            patientcolors = ht_colors,
                            filename = filename)
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```

Some investigations may have been finished at this point, receiving the DEGs. Additionally, we provide a table containing annotations like gene symbols and the results from the limma analysis including log2 fold changes and the adjusted p-values. 

TODO  combining table deg_info and deg_results

```{r}
deg_info <- sigident::exportDEGannotations_(mergedset = mergedset,
                                            genes = genes,
                                            idtype = idtype)
data.table::fwrite(deg_info, paste0(csvdir, "DEG_info.csv"))
```

```{r}
dim(deg_info)
knitr::kable(head(deg_info))
```

```{r}
deg_results <- sigident::limmaTopTable_(mergeset = mergeset,
                                        design = design,
                                        qValue = FDR)
data.table::fwrite(deg_results, paste0(csvdir, "DEG_results.csv"))
```

```{r}
dim(deg_results)
knitr::kable(head(deg_results))
```

# Gene enrichment 

A common investigation regarding differentially expressed genes analysis is the functional annotation of the DEGs. Furthermore, it is useful to find out if the DEGs are associated with  biological processes or molecular functions. 

TODO do we need this any more regarding the removal of duplicated entrez-IDs in former step?

```{r}
deg_entrez <- unique(mergedset@featureData@data$ENTREZ_GENE_ID)
deg_entrez <- deg_entrez[deg_entrez != ""]
```


## Test for over-representation 

For the identification of enriched GO terms and KEGG pathways a over-representation analysis is performed based on linear models. As input it needs the Entrez-IDs and the definition of the species. `extractGOterms_` and `extractKEGGterms` outputs a table conatining the most significant top GO and KEGG terms. In either case, rows are sorted by the minimum p-value with   
* Term: GO term  
* (Pathway: KEGG pathway)
* Ont: ontology that GO term belongs to  
* N: number of genes in the GO term  
* DE: number of genes in the input Entrez Gene IDs (deg_entrez)  
* P.DE: p-value for over-representation of the GO term in the set

```{r}
enr_topgo <- sigident::extractGOterms_(gene = deg_entrez,
                                       species = species)
```
```{r}
dim(enr_topgo)
knitr::kable(head(enr_topgo))
```


```{r}
enr_topkegg <- sigident::extractKEGGterms_(gene = deg_entrez,
                                           species = species)
data.table::fwrite(enr_topkegg, paste0(csvdir, "Top_KEGG.csv"))
```
```{r}
dim(enr_topkegg)
knitr::kable(head(enr_topkegg))
```


The following test for over-representation is based on the same method, but also taking into account for over and under expression in enriched terms with
* Term: GO term  
* Ont: ontology that GO term belongs to  
* N: number of genes in the GO term  
* Up: number of up-regulated DEGs  
* Down: number of down-regulated DEGs
* P.Up: p-value for over-representation of GO term in up-regulated genes  
* P.Down: p-value for over-representation of GO term in down-regulated genes

```{r}
enr_fitlm <- sigident::goDiffReg_(mergeset = mergeset,
                                  idtype = idtype,
                                  design = design,
                                  entrezids = mergedset@featureData@data$ENTREZ_GENE_ID)

enr_fitlm_topgo <- sigident::extractGOterms_(gene = enr_fitlm,
                                             species = species,
                                             FDR = 0.01)
data.table::fwrite(enr_fitlm_topgo, paste0(csvdir, "Top_GO_fitlm.csv"))
```
```{r}
dim(enr_fitlm_topgo)
knitr::kable(head(enr_fitlm_topgo))
```

```{r}
enr_fitlm_topkegg <- sigident::extractKEGGterms_(gene = enr_fitlm,
                                                 species = species)
data.table::fwrite(enr_fitlm_topkegg, paste0(csvdir, "Top_KEGG_fitlm.csv"))
```
```{r}
dim(enr_fitlm_topkegg)
knitr::kable(head(enr_fitlm_topkegg))
```

## GO Analysis

TODO Description here.

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
enr_analysis <- sigident::goEnrichmentAnalysis_(gene = deg_entrez,
                                                OrgDB = OrgDb,
                                                organism = organism,
                                                fitlm = enr_fitlm,
                                                pathwayid = pathwayid,
                                                species = organism,
                                                plotdir = plotdir)
```
```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "/", organism, "04110.png")
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```
```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "/", organism, "04110.pathview.png")
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

TODO Description here.

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "Enriched_GO.png")
sigident::createEnrichtedBarplot_(enrichmentobj = enr_analysis$go,
                                  type = "GO",
                                  filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

TODO Description here.

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "Enriched_KEGG.png")
sigident::createEnrichtedBarplot_(enrichmentobj = enr_analysis$kegg,
                                  type = "KEGG",
                                  filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```


# Identification of diagnostic signatures 

A common task regarding gene expression data is to distuingishing between different groups or subtypes. For this a multi-gene classifier trained using a large amount of expression data is required. Due to the superiority of features over observations an appropriate method is needed. The lasso and elastic net regularization to fit generalied linear models are powerfull and versatile methods for feature selection and is well suited to genomic data with p>>n. Therefore, we implemented the elastic net regularization method for the identification of a diagnostic multi-gene signature.  

## Split data into training and test dataset

A statistical prediction model is usually trained on 70%-80% percent of the present data. `createTrainingTest` randomly splits the merged data set into a training and a test set with the former defined value `split` regarding to a balanced distribution of the groups (here diagnosis). 

```{r}
training_list <- sigident::createTrainingTest_(diagnosis = diagnosis,
                                               mergeset = mergeset,
                                               split = split,
                                               seed = seed)
```

## Lasso regression

Regularization requires the selection of a tuning parameter (lambda) that determines the strength of regularization. The function `signature_` performs `nfolds` cross-validation selecting for best lambda and additionally builds the predictive model. `seed` is set for reproducibility. The plot depicts the mean squared error as the criteron for the 10-fold cross-validation and shows the optimal values of lambda and the appropriate number of selected features (genes) above the plot. The left dashed vertical line represents the log of the optimal value of lambda, which results in the lowest prediction error and giving the most accurate model. The right dashed vertical line indicates the log of the lambda value resulting in a model with the smallest number of included variables but also lies within one standard error of the optimal value of lambda.   
At least a ROC curve is plotted to visualize the performance measurement of the model.

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
diagnostic_lasso <- sigident::signature_(traininglist = training_list,
                                         type = "lasso",
                                         nfolds = 10,
                                         seed = seed)
filename <- paste0(plotdir, "CV_lasso.png")
sigident::createCVPlot_(cv_obj = diagnostic_lasso$fitCV,
                        filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "ROC_Lasso.min.png")
sigident::createROCplot_(roc = diagnostic_lasso$roc.min,
                         filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "ROC_Lasso.1se.png")
sigident::createROCplot_(roc = diagnostic_lasso$roc.1se,
                         filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```


## Elastic net regression 

The elastic net is a mixture of lasso and ridge regularization shrinking coefficients (like in ridge regression) and set some coefficients to zero (as in lasso). Therefore, the mixing parameter alpha needs to be determined as value between 1 (for lasso) and 0 (for ridge). A grid search for calculating optimal alpha and lambda can be conducted (as it is done next) but might take much computing capacity, hence we propose setting alpha manually to 0.9. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
diagnostic_elasticnet <- sigident::signature_(traininglist = training_list,
                                              type = "elastic",
                                              alpha = 0.9,
                                              nfolds = 10,
                                              seed = seed)
filename <- paste0(plotdir, "CV_elasticNet.png")
sigident::createCVPlot_(cv_obj = diagnostic_elasticnet$fitCV,
                        filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "ROC_elasticNet.min.png")
sigident::createROCplot_(roc = diagnostic_elasticnet$roc.min,
                         filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
filename <- paste0(plotdir, "ROC_elasticNet.1se.png")
sigident::createROCplot_(roc = diagnostic_elasticnet$roc.1se,
                         filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```


## Gridsearch to find alpha and lambda

Setting `type = "grid"` conducts a grid search calculating a pair of alpha and lambda that minimizes the CV error. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
diagnostic_glmGrid <- sigident::signature_(traininglist = training_list,
                                           type = "grid",
                                           nfolds = 10,
                                           seed = seed)
# plot model of gridsearch
filename <- paste0(plotdir, "Gridsearch_model.png")
sigident::createGridModelPlot_(model = diagnostic_glmGrid$caret.train,
                               filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# plot variable importance of gridsearch
filename <- paste0(plotdir, "Gridsearch_variable_importance.png")
sigident::createGridVarImpPlot_(model = diagnostic_glmGrid$caret.train,
                                filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# create roc plot
filename <- paste0(plotdir, "ROC_elasticNet.grid.png")
sigident::createROCplot_(roc = diagnostic_glmGrid$roc.elasticNet,
                         filename = filename)
```
```{r out.width='80%'}
knitr::include_graphics(filename)
```

# Analysis of Diagnostic Models 

## Comparing Model Performance  

These builded models can be included into a list and the performance metrices for classification can then be printed using the function `compareDiagnosticModels()`.

```{r}
diagnosticModels <- list(
  lasso.min = list(model = diagnostic_lasso$lambda.min,
                   confmat = diagnostic_lasso$confmat.min,
                   auc = as.numeric(diagnostic_lasso$roc.min$auc)),
  lasso.1se = list(model = diagnostic_lasso$lambda.1se,
                   confmat = diagnostic_lasso$confmat.1se,
                   auc = as.numeric(diagnostic_lasso$roc.1se$auc)),
  elastic.min = list(model = diagnostic_elasticnet$lambda.min,
                     confmat = diagnostic_elasticnet$confmat.min,
                     auc = as.numeric(diagnostic_elasticnet$roc.min$auc)),
  elastic.1se = list(model = diagnostic_elasticnet$lambda.1se,
                     confmat = diagnostic_elasticnet$confmat.1se,
                     auc = as.numeric(diagnostic_elasticnet$roc.1se$auc)),
  elastic.grid = list(model = diagnostic_glmGrid$elasticNet.auto,
                      confmat = diagnostic_glmGrid$confmat.elasticNet,
                      auc = as.numeric(diagnostic_glmGrid$roc.elasticNet$auc))
  )
```

```{r}
knitr::kable(
  sigident::compareDiagnosticModels(diagnosticModels)
)
```

## Model performance measurement

Additionally, the confusion matrix and the calculated perfomance metrices can be printed out for the different models, respectively. 

### Lasso (min)

```{r}
diagnosticModels$lasso.min$confmat
```

### Lasso (1se)

```{r}
diagnosticModels$lasso.1se$confmat
```

### Elastic (min)

```{r}
diagnosticModels$elastic.min$confmat
```

### Elastic (1se)

```{r}
diagnosticModels$elastic.1se$confmat
```

### Elastic net (grid search)

```{r}
diagnosticModels$elastic.grid$confmat
```


## Export selected Entrez-IDs

The following function enables the extraction of the selected genes as csv file.

```{r}
# map selected variables and export 
signature_genes <- sigident::geneMapSig_(mergeset = mergeset, model = diagnostic_lasso$lambda.min)
data.table::fwrite(signature_genes, paste0(csvdir, "signature_genes_model1.csv"))
```

```{r}
dim(signature_genes)
head(signature_genes)
```


# Identification of Prognostic Signature

## Create a list that contains specifications of the study/studies that contain(s) survival time information 

For the calculation of a prognostic signature it is first required to transform the phenoData containing the relevant survival data. In our example only the study GSE19188 contains survival data. For this the levels of the required columns (`alive`, `deceased`, `na`) need to entitled equal to their entries. Same applies to `targetcolname`, `controllevelname`, `targetlevelname` indicating the groups to be seperated. 

```{r eval = TRUE}
discoverystudies.w.timedata <- list("GSE19188" = list(timecol = "characteristics_ch1.2",
                                                      status = list(statuscol = "characteristics_ch1.3",
                                                                    levels = list(alive = "status: alive",
                                                                                  deceased = "status: deceased",
                                                                                  na = "status: Not available")),
                                                      targetcolname = "characteristics_ch1",
                                                      controllevelname = "tissue type: healthy",
                                                      targetlevelname = "tissue type: tumor"))
```


## Identification of survival correlated genes 

### Extract survival data 

Next the survival data needs to be extracted and to get into the right format. `getSurvivalTime` takes over this task resulting an a table `survivalData` containg samples (in our example of the class tumor) as rows, survival time and if a event (death) happened as columns. Additionally, the expression values for the selected DEGs are added as columns to the table. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}

### Identification of survival correlated genes
survivalData <- sigident::getSurvivalTime_(studyMetadata = studyMetadata,
                                           sampleMetadata = sampleMetadata,
                                           genes = genes,
                                           idtype = idtype,
                                           discoverystudies.w.timedata = discoverystudies.w.timedata,
                                           targetname = targetname,
                                           controlname = controlname,
                                           targetcol = targetcol,
                                           datadir = datadir)
survTable <- survivalData[["GSE19188"]]$survtable
ids <- survivalData[["GSE19188"]]$ids
```

```{r}
dim(survTable)
head(survTable[,1:4])
```

### Compute univariate cox regression 

Subsequently, univariate Cox regression is conducted to identify survival correlated genes. The results containing the hazard rate with 95% CI and p-value is exported as csv-file. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
surv_correlated <- sigident::univCox_(survtable = survTable,
                                      ids = ids)
# export table with survival correlated genes
data.table::fwrite(surv_correlated, paste0(csvdir, "survival_correlated_genes.csv"))
```

TODO here we have a difference compared with compiled vignette 

```{r}
dim(surv_correlated)
head(surv_correlated)
```


## Prognostic classifier and Kaplan-Meier estimator

To build an unbiased classifier that classfies patients into high and low risk groups expression data from the other studies are required. 

### Evaluate expression pattern (over-/underrepresentation)

The classifier is built taking into account the expression profiles of the identified survival correlated genes between tumor and non-tumor samples. 

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
classifier_studies <- c("GSE18842", "GSE19804")
exprPattern <- sigident::generateExpressionPattern_(classifier_studies = classifier_studies,
                                                    sigCov = surv_correlated,
                                                    mergeset = mergeset,
                                                    studyMetadata = studyMetadata,
                                                    sampleMetadata = sampleMetadata,
                                                    controlname = controlname,
                                                    targetname = targetname,
                                                    targetcol = targetcol)
```

```{r}
dim(exprPattern)
head(exprPattern)
```

### Apply the prognostic classifier on validation data set

#### Create a list that contains specifications of the study that contains the validation information

```{r eval = TRUE}
validationstudiesinfo <- list("GSE30219" = list(timecol = "characteristics_ch1.9",
                                                status = list(statuscol = "characteristics_ch1.8",
                                                              levels = list(alive = "status: ALIVE",
                                                                            deceased = "status: DEAD",
                                                                            na = "status: NTL")),
                                                targetcolname = "source_name_ch1",
                                                controllevelname = "Non Tumoral Lung",
                                                targetlevelname = "Lung Tumour"),

                              "GSE50081" = list(timecol = "characteristics_ch1.8",
                                                status = list(statuscol = "characteristics_ch1.9",
                                                              levels = list(alive = "status: alive",
                                                                            deceased = "status: dead",
                                                                            na = NA)),
                                                targetcolname = "characteristics_ch1.1",
                                                targetlevelname = NULL,
                                                controllevelname = NULL))
# if targetlevelname == NULL, the expression set will not be filtered further
# but instead, all samples will be used for calculations
```

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
pC <- sigident::prognosticClassifier_(PatternCom = exprPattern,
                                      validationstudiesinfo = validationstudiesinfo,
                                      datadir = datadir,
                                      idtype = idtype,
                                      controlname = controlname,
                                      targetname = targetname,
                                      targetcol = targetcol)
```

### Validation study: GSE30219

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
fit <- pC[["GSE30219"]]$kaplan.estimator$fit
RiskTable <- pC[["GSE30219"]]$risktable
```

```{r}
dim(RiskTable)
head(RiskTable)
```

#### View proportional hazards regression models

```{r}
pC[["GSE30219"]]$kaplan.estimator$res.cox
```

```{r}
fit
```


#### Plot prognostic Kaplan-Meier plot

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# create roc plot
filename <- paste0(plotdir, "GSE30219_Prognostic_Kaplan-Meier_Plot.png")
sigident::createSurvPlot_(fit = fit,
                          RiskTable = RiskTable,
                          filename = filename)
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```

### Validation study: GSE50081

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
fit <- pC[["GSE50081"]]$kaplan.estimator$fit
RiskTable <- pC[["GSE50081"]]$risktable
```

```{r}
dim(RiskTable)
head(RiskTable)
```

#### View proportional hazards regression models

```{r}
pC[["GSE50081"]]$kaplan.estimator$res.cox
```

```{r}
fit
```


#### Plot prognostic Kaplan-Meier plot

```{r results='hide', message=FALSE, warning=FALSE, error=FALSE}
# create roc plot
filename <- paste0(plotdir, "GSE50081_Prognostic_Kaplan-Meier_Plot.png")
sigident::createSurvPlot_(fit = fit,
                          RiskTable = RiskTable,
                          filename = filename)
```

```{r out.width='80%'}
knitr::include_graphics(filename)
```

# An alternative workflow: two generic functions for signature identification 

In order to simplify the whole abovedescribed workflow, we wrapped all these functions into a few big functions.

## Preprocessing: 

The preprocessing needs to be conform with the above described approach.

### Define Variables

```{r}
# initialize filePath:
filePath <- tempdir()
maindir <- "./geodata/"
datadir <- paste0(maindir, "data/")
dir.create(maindir)
dir.create(datadir)

# initialize more infos on the study
targetcol <- "target" # should be named "target"
controlname <- "Control"
targetname <- "Lung Cancer"

# define more variables
plotdir <- "./plots/"
dir.create(plotdir)
csvdir <- "./csv/"
dir.create(csvdir)

# pathway
species <- "Hs"
OrgDb <- "org.Hs.eg.db"
organism <- "hsa"
pathwayid <- "hsa04110"

# diagnostig signature
seed <- 111
split <- 0.8
nfolds <- 10

# other variables
idtype = "affy"
FDR <- 0.05
```


## Create Diagnosis, Design and Batch

```{r eval = FALSE}
dd <- sigident::createDiagnosisDesignBatch_(sampleMetadata = sampleMetadata,
                                            studyMetadata = studyMetadata,
                                            controlname = controlname,
                                            targetname = targetname,
                                            targetcol = targetcol)
diagnosis <- dd$diagnosis
design <- dd$design
batch <- dd$batch
```

## Create `mergeset`

```{r eval = FALSE}
mergeset <- sigident::batchCorrection_(mergedset = mergedset,
                                       batch = batch,
                                       design = design,
                                       idtype = idtype)
```



## Run `sigidentDEG`-function

```{r eval = FALSE}
genes <- sigidentDEG(mergeset = mergeset,
                     mergedset = mergedset,
                     studyMetadata = studyMetadata,
                     sampleMetadata = sampleMetadata,
                     targetcol = targetcol,
                     controlname = controlname,
                     design = design,
                     idtype = idtype,
                     FDR = FDR,
                     plotdir = plotdir,
                     csvdir = csvdir)
```

## Run `sigidentEnrichment`-function

```{r eval = FALSE}
sigidentEnrichment(mergeset = mergeset,
                   mergedset = mergedset,
                   idtype = idtype,
                   design = design,
                   species = species,
                   OrgDB = OrgDb,
                   organism = organism,
                   pathwayid = pathwayid,
                   plotdir = plotdir,
                   csvdir = csvdir)
```
```{r eval = FALSE}
filename <- paste0(plotdir, "/", organism, "04110.png")
knitr::include_graphics(filename)
```
```{r eval = FALSE}
filename <- paste0(plotdir, "/", organism, "04110.pathview.png")
knitr::include_graphics(filename)
```


## Run `sigidentDiagnostic`-function 


```{r eval = FALSE}
diagnosticModels <- sigidentDiagnostic(mergeset = mergeset,
                                        diagnosis = diagnosis,
                                        seed = seed,
                                        nfolds = nfolds,
                                        split = split,
                                        plotdir = plotdir)
```

```{r eval = FALSE}
knitr::kable(
  sigident::compareDiagnosticModels(diagnosticModels)
)
```

## Run `sigidentPrognostic`-Function 

### First, define Meta information lists

```{r eval = FALSE}
discoverystudies.w.timedata <- list("GSE19188" = list(timecol = "characteristics_ch1.2",
                                                      status = list(statuscol = "characteristics_ch1.3",
                                                                    levels = list(alive = "status: alive",
                                                                                  deceased = "status: deceased",
                                                                                  na = "status: Not available")),
                                                      targetcolname = "characteristics_ch1",
                                                      controllevelname = "tissue type: healthy",
                                                      targetlevelname = "tissue type: tumor"))
```

```{r eval = FALSE}
validationstudiesinfo <- list("GSE30219" = list(timecol = "characteristics_ch1.9",
                                                status = list(statuscol = "characteristics_ch1.8",
                                                              levels = list(alive = "status: ALIVE",
                                                                            deceased = "status: DEAD",
                                                                            na = "status: NTL")),
                                                targetcolname = "source_name_ch1",
                                                controllevelname = "Non Tumoral Lung",
                                                targetlevelname = "Lung Tumour"),

                              "GSE50081" = list(timecol = "characteristics_ch1.8",
                                                status = list(statuscol = "characteristics_ch1.9",
                                                              levels = list(alive = "status: alive",
                                                                            deceased = "status: dead",
                                                                            na = NA)),
                                                targetcolname = "characteristics_ch1.1",
                                                targetlevelname = NULL,
                                                controllevelname = NULL))
# if targetlevelname == NULL, the expression set will not be filtered further
# but instead, all samples will be used for calculations
```

### Then run the analysis 

```{r eval = FALSE}
progn_results <- sigident::sigidentPrognostic(mergeset = mergeset,
                                              studyMetadata = studyMetadata,
                                              sampleMetadata = sampleMetadata,
                                              discoverystudies.w.timedata = discoverystudies.w.timedata,
                                              classifier_studies = c("GSE18842", "GSE19804"),
                                              validationstudiesinfo = validationstudiesinfo,
                                              idtype = idtype,
                                              genes = genes,
                                              controlname = "Control",
                                              targetname = "Lung Cancer",
                                              datadir = datadir,
                                              plotdir = "./plots/",
                                              csvdir = "./tables/",
                                              targetcol = "target")
```

```{r eval = FALSE}
# create roc plot
filename <- paste0(plotdir, "Prognostic_Kaplan-Meier_Plot.png")
sigident::createSurvPlot_(fit = progn_results$GSE19188$GSE30219$fit,
                          RiskTable = progn_results$GSE19188$GSE30219$risktable,
                          filename = filename)
```

```{r eval = FALSE}
knitr::include_graphics(filename)
```

# References 

[1] W.E. Johnson, C. Li, and A. Rabinovic. Adjusting batch effects in microarray data using empirical bayes methods. Biostatistics, 8(1):118â€“127, 2007.
